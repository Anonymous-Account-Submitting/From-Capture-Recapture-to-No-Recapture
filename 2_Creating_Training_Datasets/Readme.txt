The following contains several notebooks made to create the training datasets for the generative model by extracting information from EM emissions of the training programs and the code.

Remove dislocated signals: This is executed first and is simply to remove the very few bad emission instances during capturing where there is bad time displacement do to slight movement of the EM antenna or digitation of the oscilloscope errored.
1_Tokenizer_Setup: Create a tokenizer reference in order so the instruction to index number is exactly the same throughout the experiments.
2_Extract_Important_Information: create methods to extract all the assembly code instructions in order/sequence, the operands and the register values at each point of execution based on a created script to run through the assembly code.
3_Obtain_Complete_Signals: disects the emissions of programs to get the exact necessary portions. For example, most of the emissions contains some additional information before the first instruction execution, which should be removed as this isnt part of the actual program. Additionally, the segments to add from the baseline program (before update) is extracted here for later appending on the generated signals.
4_Method_to_Create_X_and_y_Training_Dataset: This takes all of the extracted information from the 2_Extract_Important_Information and the EM emissions that past through "Remove dislocated signals" and "3_Obtain_complete_Signals" to create a method that will dissect the exact sequences of prior and matched instructions, operands and register values at the point of execution of every assembly instruction in the training program codes along with the corresponding real expected EM emission of the cycle the instructions produce. This is to create a viable and accurate x, y training dateset to train the generative models on.
5_Create_Balanced_Training_Dataset: This create a method that will (after creating the x and y from "4_Method_to_Create_X_and_y_Training_Dataset) take the x and y instances and makes sure that each x, y correspondence is traing on equally each epoch. This is to improve accuracy and not over train on very commonly seen and executed sequences of instructions. Note, that after each epoch, the method created can be called again to reshuffle and obtain new instance of x,y correct corresponding instances as to avoid over training on y instances when there are others to pull from.
